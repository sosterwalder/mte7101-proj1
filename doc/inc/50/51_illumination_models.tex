% -*- coding: UTF-8 -*-
% vim: autoindent expandtab tabstop=4 sw=4 sts=4 filetype=tex
% chktex-file 27 - disable warning about missing include files

\section{Beleuchtungsmodelle}
\label{sec:illumination_models}

Sofern nicht anders vermerkt, basiert der folgende Abschnitt auf~\cite{whitted_improved_1980}[S. 343] sowie auf~\cite{hughes_computer_2013}.

Beleuchtungsmodelle beschreiben, wieviel Licht von einem sichtbaren Punkt einer Oberfläche zum Betrachter emitiert wird. In der Regel wird das Licht als Funktion in Abhängigkeit folgender Faktoren beschrieben:
\begin{itemize}
    \item Richtung der Lichtquelle \item Lichstärke
    \item Position des Betrachters
    \item Orientierung der Oberfläche
    \item Oberflächenbeschaffenheit
    \item Globale Umgebung
\end{itemize}

Es wird dabei zwischen lokalen und globalen Belechtungsmodellen unterschieden.

\subsection{Lokale Beleuchtungsmodelle}
\label{subsec:local_illumination_models}

\todo[inline]{Develop further, add gouraud.}

Lokale Beleuchtungsmodelle aggregieren Daten von benachbarten, eben lokalen, Oberflächen. Diese Modelle sind in deren Umfang allerdings limitiert, da sie normalerweise nur Lichtquellen sowie die Orientierung einer Oberfläche einbeziehen. Sie ignorieren dabei aber die globale Umgebung, in welcher sich eine Oberfläche befindet.
Dies ist dadurch bedingt, dass die traditionell verwendeten Algorithmen zur Berechnung der Sichtbarkeit von Oberflächen, über keine globalen Daten verfügen.

Als Beispiel für ein lokales Beleuchtungsmodell dient das Phong-Beleuchtungsmodell, welches von Bui-Tong Phong entwickelt wurde.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{img/phong_illustration.png}
    \caption{Illustration des Phong-Beleuchtungsmodelles\protect\footnotemark}\label{fig:phong_illustration}
\end{figure}
\footnotetext{Eigene Darstellung mittels Geogebra, angelehnt an~\cite{foley_computer_1996}[Kapitel 16, Seite 731, Abbildung 16.12]}

\todo[inline]{Scale illustration down, normalize vectors to same length}

Es beschreibt die reflektierte (Licht-) Intensität als Zusammensetzung aus der ambienten, der diffusen und der ideal spiegelnden Reflexion einer Oberfläche:

\begin{gather}
    I = I_{\text{ambient}} + I_{\text{diffuse}} + I_{\text{specular}} + I_{\text{emissive}}
\end{gather}

oder mathematisch ausgedrückt:

\begin{gather}
    I(\vv{V}) = k_{a} \cdot L_{a} +
                k_{d} \displaystyle\sum_{i=0}^{n - 1} L_{i} \cdot (\vv{S_{i}} \cdot \vv{N}) +
                k_{s} \displaystyle\sum_{i=0}^{n - 1} L_{i} \cdot {(\vv{R_{i}} \cdot \vv{V})}^{k_{e}}
\end{gather}

wobei gilt:

\begin{itemize}
    \item $I(\vv{V})$:              Die reflektierte (Licht-) Intensität in Richtung des Vektors $\vv{V}$
    \item $n$:                      Anzahl Lichtquellen
    \item $k_{a} \cdot L_{a}$:      Ambiente Komponente des
                                    Beleuchtungsmodelles. Mittels diesem Faktor
                                    wird versucht allem indirekten Licht der
                                    Szene gerecht zu werden.
    \item $k_{d}$:                  Konstante für die diffuse Komponente des
                                    reflektierten Lichtes, basierend auf der
                                    Wellenlänge bzw. Frequenz
    \item $\vv{S_{i}}$:             Richtung, in welcher das Licht der $i$-ten
                                    Lichtquelle ankommt, normalisierter
                                    Einheitsvektor
    \item $\vv{N}$:                 Einheitsnormale der Oberfläche
    \item $k_{s}$:                  Koeffizient der spiegelenden Komponente,
                                    basierend auf der Wellenlänge bzw. Frequenz
    \item $\vv{R_{i}}$:             Richtung, in welcher das Licht der $i$-ten
                                    Lichtquelle reflektiert wird,
                                    normalisierter Einheitsvektor
    \item $\vv{V}$:                 Blickrichtung des Betrachters bzw.\ der
                                    Kamera
    \item $k_{e}$:                  Exponent, welcher von der Rauheit bzw.
                                    Reflektion der Oberfläche abhängt
\end{itemize}


Meist wird der emissive Term bewusst weggelassen, da dieser meist eher für
Spezialeffekte statt für die Beleuchtung ``normaler'' Objekte benutzt wird.

Der reflektive Vektor $R_{i}$ ist gegeben durch

\begin{gather}
    R_{i} = S_{i} + 2(S_{i} \cdot N)N
\end{gather}

Damit die Energieerhaltung gewährleistet ist, muss weiter $k_{d} + k_{s} < 1$
gelten. Der Winkel zwischen $\vv{R}$ und $\vv{V}$ wird mittels $\cos{\alpha}$
ermittelt.


\subsection{Globale Beleuchtungsmodelle}
\label{subsec:global_illumination_models}

Sofern nicht anders vermerkt, basiert der folgende Abschnitt auf~\cite{foley_computer_1996}[S. 775ff]

Globale Beleuchtungsmodelle beschreiben die reflektierte (Licht-) Intensität
eines Punktes aufgrund direkter Lichteinstrahlung durch Lichtquellen sowie
durch alles Licht, welches diesen Punkt nach Reflektion von bzw. Durchdringen
der eigenen oder anderer Oberflächen erreicht.

Bei globalen Beleuchtungsmodellen unterscheidet man zwischen
blickwinkelabhängigen Algorithmen, wie etwa Ray Tracing, und zwischen
blickwinkelunabhängigen Algorithmen, wie etwa Photon Mapping.

Blickwinkelabhängige Algorithmen verwenden eine Diskretisierung der sichtbaren
Fläche bzw. Bildfläche um zu entscheiden, an welchen Punkten, in Blickrichtung
des Betrachters, die Beleuchtungsberechnung durchgeführt werden soll.
Blickwinkelunabhängige Algorithmen hingegen diskretisieren und verarbeiten die
Umgebung um genügend Informationen für die Beleuchtungsberechnung zu haben.
Dies erlaubt ihnen die Beleuchtungsberechnung an einem beliebigen Punkt aus
einer beliebigen Blickrichtung.

Beide Arten von Algorithmen haben jedoch Vor- und Nachteile. So sind
blickwinkelabhängige Algorithmen gut geeignet um Spiegelungen, basierend auf
der Blickrichtung des Betrachtes, zu berechnen, eignen sich aber weniger um
gleichbleibende diffuse Anteile über weiter Flächen eines Bildes zu berechnen.
Bei blickwinkelabhängigen Algorithmen verhält es sich genau umgekehrt.

\subsubsection{Renderinggleichung}
\label{ssubsec:rendering_equation}

Die unter~\ref{subsec:global_illumination_models} genannten Verfahren versuchen
auszudrücken, wie sich Licht von einem Punkt im Raum zu einem anderen bewegt.
Dabei beschreiben sie die Intensität des Lichtes, ausgehend vom ersten Punkt
zum zweiten Punkt. Zusätzlich wird die Intensität des Lichtes, ausgehend von
allen anderen Punkten, welche den ersten Punkt erreichen, und zum zweiten Punkt
emitiert werden, beschrieben.

James (Jim) Kajiya stellte 1986 die so genannte Renderinggleichung auf, welche
genau dieses Verhalten beschreibt~\cite{kajiya_rendering_1986}
und~\cite{foley_computer_1996}:
\begin{equation}
    I(x, x') = g(x, x')[\varepsilon(x, x') + \int\limits_{S}\rho(x, x', x'')I(x', x'')dx'']
\end{equation}
wobei gilt:

\begin{itemize}
    \item $x, x' \text{und } x''$: Punkte in der Umgebung
    \item $ I(x, x')$:            Lichtintensität von Punkt $x'$ nach Punkt $x$
    \item $ g(x, x')$:            Ein auf die Geometrie bezogener Term\\
                                  \hspace*{4mm} $0$:     \hspace*{6mm} $x$ und $x'$ verdecken sich\\
                                  \hspace*{4mm} $1/r^2$: \hspace*{1mm} $x$ und $x'$ sehen sich, wobei $r$ die Distanz zwischen $x$ und $x'$ ist
    \item $\epsilon(x, x')$:      Intensität des Lichtes, welches von $x'$ nach $x$ emitiert wird
    \item $\rho(x, x', x'')$:     Intensität des Lichtes, welches von $x''$
                                  durch die Oberfläche bei $x'$ nach $x$
                                  gestreut wird
    \item $\int\limits_{S}$:      Integral über die Vereinigung aller Flächen,
                                  daher $ S = \bigcup{S_{i}} $\\
                                      Dies bedeutet, dass die Punkte $x$, $x'$
                                      und $x''$ über alle Flächen aller Objekte
                                      der Szene ``streifen''.  Wobei es sich
                                      bei $S_{0}$ um eine zusätzliche Fläche
                                      handelt, welche als Hintergrund verwendet
                                      wird.  $S_{0}$ ist dabei eine Hemisphäre,
                                      welche die gesamte Szene umspannt.
\end{itemize}

\section{Ray Casting und Ray Tracing}
\label{sec:ray_casting_tracing}

\todo[inline]{Expand this section. Add formulas as well as examples.}
\todo[inline]{Punkte mehr ausführen; Integration zeigen mit Diskretition; auch Berechnungen}

Sofern nicht anders vermerkt, basiert der folgende Abschnitt
auf~\cite{hughes_computer_2013}[Kapitel 15, S. 387ff].\\
\\
Um ein Bild möglichst realistisch darzustellen muss berechnet werden, wieviel
Licht zu jedem Pixel der sichtbaren Bildfläche (also dem Betrachter)
transportiert wird. Da Photonen die Energie des Lichtes transportieren, muss
man also das physikalische Verhalten dieser simulieren. Es ist allerdings nicht
möglich \textit{alle} Photonen zu simulieren, da der Aufwand schlicht zu gross
wäre. Daher macht es Sinn nur einige Photonen (exemplarisch) zu betrachten und
dann eine Abschätzung des gesamten Lichtes vorzunehmen.\\

\subsection{Ray Casting}
\label{subsec:ray_casting}

Bei \textbf{Ray Casting} handlt es sich grundsätzlich um eine Strategie zur
Simulation, wieviel Licht anhand eines (Licht-) Strahles zu der sichtbaren
Bildfläche (also dem Betrachter) transportiert wird.

\begin{figure}[H]
    \centering \rotatebox{0}{\scalebox{0.3}[0.3]{\includegraphics{img/ray_tracing_01.png}}}
    \caption{Punkt $P$ auf einer Oberfläche eines Dreieckes, welcher für die Kamera bzw.\ den Betrachter sichtbar ist.
        Der Betrachter nimmt dabei das Licht, welches aus verschiedenen Richtungen $\omega_{i}$ kommt, über den Punkt $P$ in Richtung $\omega_{0}$ wahr.\label{fig:ray_casting:basics}\protect\footnotemark}
\end{figure}
\footnotetext{Darstellung von~\cite{hughes_computer_2013}[Kapitel 15, Seite 389, Abbildung 15.1]}

Wie in Abbildung~\ref{fig:ray_casting:basics} ersichtlich, gelangt Licht aus vielen Richtungen durch den Punkt $P$ zu dem Betrachter. Dies beinhaltet auch die Möglichkeit, dass
Licht nicht nur von einer Lichtquelle aus, sondern von vielen Lichtquellen aus via $P$ zum Betrachter gelangt. Weiter ist es möglich, dass Licht zuvor an anderen Punkten gestreut
und/oder gespiegelt und erst dann via $P$ zum Betrachter gelangte.\\
\\
Dies führt zu den folgenden Schlussfolgerungen:
\begin{itemize}
    \item Es müssen alle möglichen Richtungen, aus denen Licht kommen könnte,
        an Punkt $P$ untersucht werden.
    \item Da, bedingt durch technische Limitierungen, nur diskretes Abtasten
        möglich ist, müssen die Richtungen auf eine endliche Anzahl beschränkt
        werden, was zu Abtastfehlern führen kann.
\end{itemize}
Um die Abtastfehler zu minieren, können die Richtungen des Abtasten anhand der Lichtquellen priorisiert werden.

\newpage{}

Ein möglicher Algorithmus, wie solch ein Verfahren umgesetzt werden kann,
findet sich in~\ref{fig:ray_casting:high_level}.

\begin{lstlisting}[language=Python,caption={Eine abstrakte Umsetzung des Ray
        Castings\protect\footnotemark.},label={fig:ray_casting:high_level},captionpos=b,emph={ray_cast}]
def ray_cast():
    # "pixels" is a list of all pixels of the image plane
    for pixel in pixels:
        # Save all intersections for given pixel
        intersections = []

        # Returns the ray passing through the given
        # pixel from the eye
        ray = ray_at_pixel(pixel)

        # "scene_triangles" is a list of all triangles
        # coming from meshes contained in the scene to render
        for triangle in scene_triangles:
            p   = intersect(ray, triangle)
            sum = 0

            for light in incoming_lights_at_p:
                sum = sum + l.value
            end

            if is_smallest_intersection(p, intersections):
                pixel = sum
            intersections.append(p)
\end{lstlisting}
\footnotetext{Algorithmus in Pseudocode gemäss~\cite{hughes_computer_2013}[Kapitel 15, Seite 391, Auflistung 15.2]}

Das Verfahren wurde erstmals 1968 in~\cite{appel_techniques_1968} vorgeschlagen
und auch 1968 von der Matthematical Applications Group Inc.\
in~\cite{arlington_mathematical_applications_group_inc_afips_1968} erfolgreich umgesetzt.

\subsection{Ray Tracing}
\label{subsec:ray_tracing}

Bei dem heute als Ray Tracing bekannten Verfahren, handelt es sich um eine
verbesserte Version des unter~\ref{subsec:ray_casting} genannten Ray Casting
Verfahrens. Dieses wurde im Juni 1980 durch~\cite{whitted_improved_1980}[S.
345] verbessert.

So schlägt~\cite{whitted_improved_1980} vor, dass die Berechnung der
Sichtbarkeit (von Objekten) nicht bei dem nähesten gefundenen Schnittpunkt
abgebrochen wird, sondern dass jedes Auftreffen eines (Licht-) Strahles mehr
(Licht-) Strahlen durch Transmission bzw. Reflektion sowie in Richtung jeder
Lichtquelle gesendet werden. Dieser Prozess wird so lange wiederholt, bis
keiner der neu generierten (Licht-) Strahlen mehr auf ein Objekt
trifft~\cite{whitted_improved_1980}[S.  345].\\
Es handelt sich dabei also um ein rekursives Verfahren und wird daher
teilweise auch rekurisves Ray Tracing genannt.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{img/ray_tracing_illustration.png}
    \caption{Illustration des Ray Tracing Verfahrens\protect\footnotemark}\label{fig:ray_tracing_illustration}
\end{figure}
\footnotetext{Eigene Darstellung mittels Geogebra, angelehnt an~\cite{glassner_introduction_1989}[Kapitel 2, Seite 16, Abbildung 11; Piktogramm Auge erstellt von ``Icomoon'' auf www.flaticon.com; Piktogramm Glühbirne erstellt von ``Simpleicon'' auf www.flaticon.com;]}
\todo[inline]{Explain illustration~\ref{fig:ray_tracing_illustration}, provide
a better resolution, use bigger font, use same length for vectors}
\todo[inline]{Explain transmission and refraction}
\todo[inline]{Add an (sphere) example, explain basic terminology (illum.\ and
    shadow rays, aliasing and so on)}
